{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n1GbOyVa3fx"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWIPMq8Ta5zW"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca href=\"https://colab.research.google.com/github/google-research/rlds/blob/main/rlds/examples/rlds_reverb_patterns.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Run In Google Colab\"/\u003e\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdWJFC-AIduH"
      },
      "source": [
        "# RLDS \u0026 Reverb patterns\n",
        "\n",
        "This Colab showcases how to transform an RLDS dataset using Reverb patterns by:\n",
        "\n",
        "1. Apply a pattern directly in the dataset\n",
        "1. Apply the same pattern when inserting the steps into a Reverb table.\n",
        "\n",
        "Note that the same patterns can be applied to data collected online (for example, from running an environment), making it easier to mix online and offline experience.\n",
        "\n",
        "This colab focuses on the comparison between how to apply the patterns to RLDS and Reverb. If you are looking for details about the patterns API,  see [this colab](https://colab.research.google.com/github/google-research/rlds/blob/main/rlds/examples/rlds_dataset_patterns.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DUQVrBsbDHA"
      },
      "outputs": [],
      "source": [
        "#@title Install Pip packages\n",
        "!pip install rlds[tensorflow]\n",
        "!pip install envlogger[tfds]\n",
        "!apt-get install libgmp-dev\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 45974,
          "status": "ok",
          "timestamp": 1653326622821,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "SX2bty_P1qws"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import os\n",
        "import rlds\n",
        "import envlogger\n",
        "from envlogger.backends import rlds_utils\n",
        "from envlogger.backends import tfds_backend_writer\n",
        "from envlogger.testing import catch_env\n",
        "import numpy as np\n",
        "import reverb\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import time\n",
        "from typing import Optional, List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyTwVENR26Pv"
      },
      "source": [
        "## Generate a dataset to use throughout the examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_izO6IDuKc9G"
      },
      "source": [
        "Before experimenting with the patterns, we generate a test dataset using random actions in a Catch environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "executionInfo": {
          "elapsed": 4,
          "status": "ok",
          "timestamp": 1653326622839,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "HHiZ6haP2sfX"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/tmp/tensorflow_datasets/catch/'  # @param\n",
        "num_episodes = 20  # @param\n",
        "max_episodes_per_shard = 1000  # @param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {
          "elapsed": 43,
          "status": "ok",
          "timestamp": 1653326622892,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "MYXFYFtX3Gq1"
      },
      "outputs": [],
      "source": [
        "#@title Record Data Utils\n",
        "def record_data(data_dir, num_episodes, max_episodes_per_shard):\n",
        "  env = catch_env.Catch()\n",
        "\n",
        "  def step_fn(unused_timestep, unused_action, unused_env):\n",
        "    return {'timestamp_ns': time.time_ns()}\n",
        "\n",
        "  ds_config = tfds.rlds.rlds_base.DatasetConfig(\n",
        "      name='catch_example',\n",
        "      observation_info=tfds.features.Tensor(\n",
        "          shape=(10, 5), dtype=tf.float32,\n",
        "          encoding=tfds.features.Encoding.ZLIB),\n",
        "      action_info=tf.int64,\n",
        "      reward_info=tf.float64,\n",
        "      discount_info=tf.float64,\n",
        "      step_metadata_info={'timestamp_ns': tf.int64})\n",
        "\n",
        "  with envlogger.EnvLogger(\n",
        "      env,\n",
        "      backend=tfds_backend_writer.TFDSBackendWriter(\n",
        "          data_directory=data_dir,\n",
        "          split_name='train',\n",
        "          max_episodes_per_file=max_episodes_per_shard,\n",
        "          ds_config=ds_config),\n",
        "      step_fn=step_fn) as env:\n",
        "    print('Done wrapping environment with EnvironmentLogger.')\n",
        "\n",
        "    print(f'Training a random agent for {num_episodes} episodes...')\n",
        "    for i in range(num_episodes):\n",
        "      print(f'episode {i}')\n",
        "      timestep = env.reset()\n",
        "      while not timestep.last():\n",
        "        action = np.random.randint(low=0, high=3)\n",
        "        timestep = env.step(action)\n",
        "    print(f'Done training a random agent for {num_episodes} episodes.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "executionInfo": {
          "elapsed": 66,
          "status": "ok",
          "timestamp": 1653326622991,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "GYzvEFrb2_GF",
        "outputId": "93eacef4-43bf-40eb-eeac-e7d1682803ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done wrapping environment with EnvironmentLogger.\n",
            "Training a random agent for 20 episodes...\n",
            "episode 0\n",
            "episode 1\n",
            "episode 2\n",
            "episode 3\n",
            "episode 4\n",
            "episode 5\n",
            "episode 6\n",
            "episode 7\n",
            "episode 8\n",
            "episode 9\n",
            "episode 10\n",
            "episode 11\n",
            "episode 12\n",
            "episode 13\n",
            "episode 14\n",
            "episode 15\n",
            "episode 16\n",
            "episode 17\n",
            "episode 18\n",
            "episode 19\n",
            "Done training a random agent for 20 episodes.\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(dataset_path, exist_ok=True)\n",
        "record_data(dataset_path, num_episodes, max_episodes_per_shard)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "executionInfo": {
          "elapsed": 134,
          "status": "ok",
          "timestamp": 1653326623136,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "sZHKrwQc3CAu"
      },
      "outputs": [],
      "source": [
        "loaded_dataset = tfds.builder_from_directory(dataset_path).as_dataset(\n",
        "    split='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEmAng-t3ZF8"
      },
      "source": [
        "## Launch a Reverb server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQmbTCYvKq7_"
      },
      "source": [
        "We launch a reverb server to use later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "executionInfo": {
          "elapsed": 52,
          "status": "ok",
          "timestamp": 1653326623200,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "_rGABIn53YY5",
        "outputId": "90a6fa93-a519-424c-ba6f-f9950829a8d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[32m[Reverb] Live dashboard: http://sabela.c.googlers.com:24800\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "simple_server = reverb.Server(\n",
        "    tables=[\n",
        "        reverb.Table(\n",
        "            name='transition',\n",
        "            sampler=reverb.selectors.Uniform(),\n",
        "            remover=reverb.selectors.Fifo(),\n",
        "            max_size=int(1e6),\n",
        "            # Sets Rate Limiter to a low number for the examples.\n",
        "            # Read the Rate Limiters section for usage info.\n",
        "            rate_limiter=reverb.rate_limiters.MinSize(2),\n",
        "            # Note that instead of defining the signature explicitly, we can use \n",
        "            # reverb.structured_writer.infer_signature \n",
        "            # to get the table signature from the Reverb pattern.\n",
        "            signature={\n",
        "                'action': tf.TensorSpec([], tf.int64),\n",
        "                'observation': tf.TensorSpec([10, 5], tf.float32),\n",
        "                'next_observation': tf.TensorSpec([10, 5], tf.float32),\n",
        "            },\n",
        "        )\n",
        "    ])\n",
        "\n",
        "# Initializes the reverb client on the same port as the server.\n",
        "client = reverb.Client(f'localhost:{simple_server.port}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fngSva2774gt"
      },
      "source": [
        "# Reverb Pattern\n",
        "\n",
        "We define a pattern that takes one RLDS step and returns a transition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "executionInfo": {
          "elapsed": 9,
          "status": "ok",
          "timestamp": 1653326623221,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "Jho4KfEt74Pu"
      },
      "outputs": [],
      "source": [
        "def transition(step):\n",
        " return {\n",
        "    rlds.OBSERVATION: step[rlds.OBSERVATION][-2],\n",
        "    rlds.ACTION: step[rlds.ACTION][-2],\n",
        "    'next_observation': step[rlds.OBSERVATION][-1],\n",
        "  }\n",
        "\n",
        "step_spec = rlds.transformations.step_spec(loaded_dataset)\n",
        "pattern = reverb.structured_writer.pattern_from_transform(step_spec, transition)\n",
        "config = reverb.structured_writer.create_config(pattern, table='transition')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8ZFiaV1ATiA"
      },
      "source": [
        "# Transform dataset with the Reverb Pattern\n",
        "\n",
        "By using the `PatternDataset` or the `rlds.transformations`, it is possible to transform a stream of steps into a stream of trajectories with Reverb Patterns.\n",
        "\n",
        "If instead of one pattern you need to apply a list of patterns, check `rlds.transformations.pattern_map`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "executionInfo": {
          "elapsed": 161,
          "status": "ok",
          "timestamp": 1653326623400,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "LV8Qby8W8Nul",
        "outputId": "23ae79bc-60ce-41c3-84e9-e1ff8ccf4d6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'action': \u003ctf.Tensor: shape=(), dtype=int64, numpy=0\u003e, 'next_observation': \u003ctf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
            "array([[0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.]], dtype=float32)\u003e, 'observation': \u003ctf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
            "array([[0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.]], dtype=float32)\u003e}\n",
            "{'action': \u003ctf.Tensor: shape=(), dtype=int64, numpy=2\u003e, 'next_observation': \u003ctf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
            "array([[0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0.]], dtype=float32)\u003e, 'observation': \u003ctf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
            "array([[0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.]], dtype=float32)\u003e}\n"
          ]
        }
      ],
      "source": [
        "pattern_dataset = rlds.transformations.pattern_map_from_transform(\n",
        "    episodes_dataset=loaded_dataset,\n",
        "    transform_fn=transition,\n",
        "    respect_episode_boundaries=True\n",
        ")\n",
        "\n",
        "for transition in pattern_dataset.take(2):\n",
        "  print(transition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alGmOVs8DtXR"
      },
      "source": [
        "# Convert to trajectories by inserting in Reverb\n",
        "\n",
        "When inserting on a Reverb table, we can use the same patterns we used to transform a dataset. In this example, we apply them to an RLDS dataset, but they could also be applied to online data collected directly from an environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQWCWf0KFxfG"
      },
      "source": [
        "## Insert\n",
        "In a real case, we would have two processes, one producing data and inserting it in Reverb, and another one sampling from Reverb. For the sake of simplicity, we insert first and consider that all data comes from the dataset we created before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "executionInfo": {
          "elapsed": 416,
          "status": "ok",
          "timestamp": 1653326623829,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "I_FDUrV8FgZ5"
      },
      "outputs": [],
      "source": [
        "reverb_writer = client.structured_writer(configs=[config])\n",
        "\n",
        "for step in loaded_dataset.flat_map(lambda e: e[rlds.STEPS]):\n",
        "  reverb_writer.append(data=step)\n",
        "  if step[rlds.IS_LAST]:\n",
        "    reverb_writer.end_episode(clear_buffers=True)\n",
        "  reverb_writer.flush"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17zawzdOHQws"
      },
      "source": [
        "## Sample\n",
        "\n",
        "The data sampled from the Reverb server has the same shape as the data we obtained when applying the pattern directly to the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "executionInfo": {
          "elapsed": 56,
          "status": "ok",
          "timestamp": 1653326623901,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "L9XxUQEsHMXs",
        "outputId": "ec394c46-0ad6-469f-a4b9-1b9c3c6329be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ReplaySample(info=SampleInfo(key=\u003ctf.Tensor: shape=(), dtype=uint64, numpy=8567135249577419563\u003e, probability=\u003ctf.Tensor: shape=(), dtype=float64, numpy=0.005555555555555556\u003e, table_size=\u003ctf.Tensor: shape=(), dtype=int64, numpy=180\u003e, priority=\u003ctf.Tensor: shape=(), dtype=float64, numpy=1.0\u003e, times_sampled=\u003ctf.Tensor: shape=(), dtype=int32, numpy=1\u003e), data={'action': \u003ctf.Tensor: shape=(), dtype=int64, numpy=0\u003e, 'next_observation': \u003ctf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
            "array([[0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [1., 1., 0., 0., 0.]], dtype=float32)\u003e, 'observation': \u003ctf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
            "array([[0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.]], dtype=float32)\u003e})\n",
            "ReplaySample(info=SampleInfo(key=\u003ctf.Tensor: shape=(), dtype=uint64, numpy=18130606694345904134\u003e, probability=\u003ctf.Tensor: shape=(), dtype=float64, numpy=0.005555555555555556\u003e, table_size=\u003ctf.Tensor: shape=(), dtype=int64, numpy=180\u003e, priority=\u003ctf.Tensor: shape=(), dtype=float64, numpy=1.0\u003e, times_sampled=\u003ctf.Tensor: shape=(), dtype=int32, numpy=1\u003e), data={'action': \u003ctf.Tensor: shape=(), dtype=int64, numpy=1\u003e, 'next_observation': \u003ctf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
            "array([[0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.]], dtype=float32)\u003e, 'observation': \u003ctf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
            "array([[0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0.]], dtype=float32)\u003e})\n"
          ]
        }
      ],
      "source": [
        "reverb_dataset = reverb.TrajectoryDataset.from_table_signature(server_address=f'localhost:{simple_server.port}', table='transition', max_in_flight_samples_per_worker=1)\n",
        "\n",
        "for sample in reverb_dataset.take(2):\n",
        "  print(sample)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "rlds_reverb_patterns.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
