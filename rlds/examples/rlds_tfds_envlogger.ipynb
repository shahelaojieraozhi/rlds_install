{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCwbkVFxU5a9"
      },
      "source": [
        "# Envlogger and TFDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIQjTg467e41"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1DBTRzKDMmb"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/google-research/rlds/blob/main/rlds/examples/rlds_tfds_envlogger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Run In Google Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV4QCcHs_7aW",
        "outputId": "abcf92b4-3bd8-46c7-93d0-2fc6d3176858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rlds\n",
            "  Downloading rlds-0.1.3-py3-none-manylinux2010_x86_64.whl (37 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rlds) (1.19.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rlds) (1.0.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from rlds) (2.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->rlds) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (1.43.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (1.13.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (0.37.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (13.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (3.10.0.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (1.1.2)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (0.4.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (2.7.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (0.24.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rlds) (3.17.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->rlds) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->rlds) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->rlds) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->rlds) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->rlds) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->rlds) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->rlds) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->rlds) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->rlds) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->rlds) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->rlds) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->rlds) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->rlds) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->rlds) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow->rlds) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->rlds) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->rlds) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->rlds) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->rlds) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->rlds) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->rlds) (3.2.0)\n",
            "Installing collected packages: rlds\n",
            "Successfully installed rlds-0.1.3\n",
            "Collecting envlogger[tfds]\n",
            "  Downloading envlogger-1.0.7-cp37-cp37m-manylinux2010_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting dm-env\n",
            "  Downloading dm_env-1.5-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (1.19.5)\n",
            "Requirement already satisfied: setuptools!=50.0.0 in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (57.4.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: protobuf>=3.14 in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (3.17.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (1.0.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from envlogger[tfds]) (2.7.0)\n",
            "Collecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.5.2.dev202202110043-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 25.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.14->envlogger[tfds]) (1.15.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm-env->envlogger[tfds]) (0.1.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (3.10.0.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (13.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (1.13.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (1.43.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (0.24.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->envlogger[tfds]) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->envlogger[tfds]) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->envlogger[tfds]) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->envlogger[tfds]) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->envlogger[tfds]) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->envlogger[tfds]) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->envlogger[tfds]) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->envlogger[tfds]) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->envlogger[tfds]) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->envlogger[tfds]) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->envlogger[tfds]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->envlogger[tfds]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->envlogger[tfds]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->envlogger[tfds]) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow->envlogger[tfds]) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->envlogger[tfds]) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->envlogger[tfds]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->envlogger[tfds]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->envlogger[tfds]) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->envlogger[tfds]) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->envlogger[tfds]) (3.2.0)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->envlogger[tfds]) (5.4.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->envlogger[tfds]) (1.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->envlogger[tfds]) (4.62.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->envlogger[tfds]) (0.3.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->envlogger[tfds]) (2.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tfds-nightly->envlogger[tfds]) (1.54.0)\n",
            "Installing collected packages: toml, mock, dm-env, tfds-nightly, envlogger\n",
            "Successfully installed dm-env-1.5 envlogger-1.0.7 mock-4.0.3 tfds-nightly-4.5.2.dev202202110043 toml-0.10.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  libgmpxx4ldbl\n",
            "Suggested packages:\n",
            "  gmp-doc libgmp10-doc libmpfr-dev\n",
            "The following NEW packages will be installed:\n",
            "  libgmp-dev libgmpxx4ldbl\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 325 kB of archives.\n",
            "After this operation, 1,667 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgmpxx4ldbl amd64 2:6.1.2+dfsg-2 [8,964 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgmp-dev amd64 2:6.1.2+dfsg-2 [316 kB]\n",
            "Fetched 325 kB in 1s (509 kB/s)\n",
            "Selecting previously unselected package libgmpxx4ldbl:amd64.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../libgmpxx4ldbl_2%3a6.1.2+dfsg-2_amd64.deb ...\n",
            "Unpacking libgmpxx4ldbl:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Selecting previously unselected package libgmp-dev:amd64.\n",
            "Preparing to unpack .../libgmp-dev_2%3a6.1.2+dfsg-2_amd64.deb ...\n",
            "Unpacking libgmp-dev:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Setting up libgmpxx4ldbl:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Setting up libgmp-dev:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "#@title Install Pip packages\n",
        "!pip install rlds[tensorflow]\n",
        "!pip install envlogger[tfds]\n",
        "!apt-get install libgmp-dev\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y8fkB77rhV4d"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import os\n",
        "import rlds\n",
        "import envlogger\n",
        "from envlogger.backends import rlds_utils\n",
        "from envlogger.backends import tfds_backend_writer\n",
        "from envlogger.testing import catch_env\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import time\n",
        "from typing import Optional, List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J8UBrhHiiKug"
      },
      "outputs": [],
      "source": [
        "#@title Auxiliary function to get dataset directories\n",
        "\n",
        "_METADATA_FILENAME='features.json'\n",
        "\n",
        "def get_ds_paths(pattern: str) -> List[str]:\n",
        "  \"\"\"Returns the paths of tfds datasets under a (set of) directories.\n",
        "\n",
        "  We assume that a sub-directory with features.json file contains the dataset\n",
        "  files.\n",
        "\n",
        "  Args:\n",
        "    pattern: Root directory to search for dataset paths or a glob that matches\n",
        "      a set of directories, e.g. /some/path or /some/path/prefix*. See\n",
        "      tf.io.gfile.glob for the supported patterns.\n",
        "\n",
        "  Returns:\n",
        "    A list of paths that contain the environment logs.\n",
        "\n",
        "  Raises:\n",
        "    ValueError if the specified pattern matches a non-directory.\n",
        "  \"\"\"\n",
        "  paths = set([])\n",
        "  for root_dir in tf.io.gfile.glob(pattern):\n",
        "    if not tf.io.gfile.isdir(root_dir):\n",
        "      raise ValueError(f'{root_dir} is not a directory.')\n",
        "    print(f'root: {root_dir}')\n",
        "    for path, _, files in tf.io.gfile.walk(root_dir):\n",
        "      if _METADATA_FILENAME in files:\n",
        "        print(f'path: {path}')\n",
        "        paths.add(path)\n",
        "  return list(paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjilhMvUz5ex"
      },
      "source": [
        "# Generate a dataset\n",
        "\n",
        "In this example, we use the local TFDS backend. \n",
        "\n",
        "In order to generate the dataset, use the parameters below to configure:\n",
        "\n",
        "1. `root_dir`: where the dataset will be created.\n",
        "1. `num_episodes`: how many episodes to generate.\n",
        "1. `max_episodes_per_shard`: maximum number of episodes to include per file (episodes will be stored in multiple files and then read as a single dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l8FEjzUG0Alw"
      },
      "outputs": [],
      "source": [
        "generate_data_dir='/tmp/tensorflow_datasets/catch/' # @param\n",
        "num_episodes= 20 # @param\n",
        "max_episodes_per_shard = 1000 # @param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "epUB8Ri6qKUg"
      },
      "outputs": [],
      "source": [
        "os.makedirs(generate_data_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvD3g8eQ8i_f",
        "outputId": "3deb6e55-cf34-4bed-bd7f-e8104ca75c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done wrapping environment with EnvironmentLogger.\n",
            "Training a random agent for 20 episodes...\n",
            "episode 0\n",
            "episode 1\n",
            "episode 2\n",
            "episode 3\n",
            "episode 4\n",
            "episode 5\n",
            "episode 6\n",
            "episode 7\n",
            "episode 8\n",
            "episode 9\n",
            "episode 10\n",
            "episode 11\n",
            "episode 12\n",
            "episode 13\n",
            "episode 14\n",
            "episode 15\n",
            "episode 16\n",
            "episode 17\n",
            "episode 18\n",
            "episode 19\n",
            "Done training a random agent for 20 episodes.\n"
          ]
        }
      ],
      "source": [
        "def record_data(data_dir, num_episodes, max_episodes_per_shard):\n",
        "  env = catch_env.Catch()\n",
        "\n",
        "  def step_fn(unused_timestep, unused_action, unused_env):\n",
        "    return {'timestamp_ns': time.time_ns()}\n",
        "\n",
        "  ds_config = tfds.rlds.rlds_base.DatasetConfig(\n",
        "        name='catch_example',\n",
        "        observation_info=tfds.features.Tensor(\n",
        "            shape=(10, 5),\n",
        "            dtype=tf.float32,\n",
        "            encoding=tfds.features.Encoding.ZLIB),\n",
        "        action_info=tf.int64,\n",
        "        reward_info=tf.float64,\n",
        "        discount_info=tf.float64,\n",
        "        step_metadata_info={'timestamp_ns': tf.int64})\n",
        "\n",
        "  with envlogger.EnvLogger(\n",
        "      env,\n",
        "      backend = tfds_backend_writer.TFDSBackendWriter(\n",
        "        data_directory=data_dir,\n",
        "        split_name='train',\n",
        "        max_episodes_per_file=max_episodes_per_shard,\n",
        "        ds_config=ds_config),\n",
        "      step_fn=step_fn) as env:\n",
        "    print('Done wrapping environment with EnvironmentLogger.')\n",
        "\n",
        "    print(f'Training a random agent for {num_episodes} episodes...')\n",
        "    for i in range(num_episodes):\n",
        "      print(f'episode {i}')\n",
        "      timestep = env.reset()\n",
        "      while not timestep.last():\n",
        "        action = np.random.randint(low=0, high=3)\n",
        "        timestep = env.step(action)\n",
        "    print(f'Done training a random agent for {num_episodes} episodes.')\n",
        "\n",
        "record_data(generate_data_dir, num_episodes, max_episodes_per_shard)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RkYWg1A_8jX"
      },
      "source": [
        "# Recover a dataset\n",
        "\n",
        "When the process of generating one dataset didn't finish properly, it is possible for the last shard to be incomplete. Envlogger provides the functionality to recover this last shard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jyojLdQJAX_Z"
      },
      "outputs": [],
      "source": [
        "recover_dataset_path = '/tmp/tensorflow_datasets/catch/' # @param\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RSdPMF8V_8LP"
      },
      "outputs": [],
      "source": [
        "builder = tfds.builder_from_directory(recover_dataset_path)\n",
        "builder = rlds_utils.maybe_recover_last_shard(builder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh63bHYz_mPO"
      },
      "source": [
        "# Load one dataset\n",
        "\n",
        "Loading one dataset generated with the TFDS backend uses just regular TFDS functionality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4y2S_CaME6be"
      },
      "outputs": [],
      "source": [
        "load_dataset_path = '/tmp/tensorflow_datasets/catch/' # @param\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYbA7kX_EgSH",
        "outputId": "0f0c2c71-4d35-4a20-b15e-229042390dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n"
          ]
        }
      ],
      "source": [
        "loaded_dataset = tfds.builder_from_directory(load_dataset_path).as_dataset(split='all')\n",
        "\n",
        "for e in loaded_dataset:\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAp3HA5JFWYR"
      },
      "source": [
        "# Load a dataset from multiple directories\n",
        "\n",
        "TFDS supports loading of one dataset from multiple directories as long as the data has the same shape. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ajotTik0GJKr"
      },
      "outputs": [],
      "source": [
        "multiple_dataset_path = '/tmp/tensorflow_datasets/catch' # @param\n",
        "subdir_A = 'subdir_A' # @param\n",
        "subdir_B = 'subdir_B' # @param\n",
        "\n",
        "dir_A = os.path.join(multiple_dataset_path, subdir_A)\n",
        "dir_B = os.path.join(multiple_dataset_path, subdir_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiQ9xI3eCtzF",
        "outputId": "02ecbcb6-b739-4ef6-bbdd-b6580d9e53a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done wrapping environment with EnvironmentLogger.\n",
            "Training a random agent for 20 episodes...\n",
            "episode 0\n",
            "episode 1\n",
            "episode 2\n",
            "episode 3\n",
            "episode 4\n",
            "episode 5\n",
            "episode 6\n",
            "episode 7\n",
            "episode 8\n",
            "episode 9\n",
            "episode 10\n",
            "episode 11\n",
            "episode 12\n",
            "episode 13\n",
            "episode 14\n",
            "episode 15\n",
            "episode 16\n",
            "episode 17\n",
            "episode 18\n",
            "episode 19\n",
            "Done training a random agent for 20 episodes.\n",
            "Done wrapping environment with EnvironmentLogger.\n",
            "Training a random agent for 20 episodes...\n",
            "episode 0\n",
            "episode 1\n",
            "episode 2\n",
            "episode 3\n",
            "episode 4\n",
            "episode 5\n",
            "episode 6\n",
            "episode 7\n",
            "episode 8\n",
            "episode 9\n",
            "episode 10\n",
            "episode 11\n",
            "episode 12\n",
            "episode 13\n",
            "episode 14\n",
            "episode 15\n",
            "episode 16\n",
            "episode 17\n",
            "episode 18\n",
            "episode 19\n",
            "Done training a random agent for 20 episodes.\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(dir_A, exist_ok=True)\n",
        "os.makedirs(dir_B, exist_ok=True)\n",
        "record_data(dir_A, num_episodes, max_episodes_per_shard)\n",
        "record_data(dir_B, num_episodes, max_episodes_per_shard)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiQIocrSic0Y",
        "outputId": "5bd705fe-d87f-4baf-bf71-54fa937031e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n",
            "{'steps': <_VariantDataset shapes: {action: (), discount: (), is_first: (), is_last: (), is_terminal: (), observation: (10, 5), reward: (), timestamp_ns: ()}, types: {action: tf.int64, discount: tf.float64, is_first: tf.bool, is_last: tf.bool, is_terminal: tf.bool, observation: tf.float32, reward: tf.float64, timestamp_ns: tf.int64}>}\n"
          ]
        }
      ],
      "source": [
        "ds = tfds.builder_from_directories([dir_A, dir_B]).as_dataset(split='all')\n",
        "\n",
        "for e in ds.take(5):\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TFDS_splits_loader.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}