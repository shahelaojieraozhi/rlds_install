{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n1GbOyVa3fx"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWIPMq8Ta5zW"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca href=\"https://colab.research.google.com/github/google-research/rlds/blob/main/rlds/examples/rlds_dataset_patterns.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Run In Google Colab\"/\u003e\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdWJFC-AIduH"
      },
      "source": [
        "# RLDS Dataset Patterns\n",
        "\n",
        "This Colab showcases how to transform an RLDS dataset using Reverb patterns by applying a pattern directly to the dataset.\n",
        "\n",
        "If you are looking for examples on how to apply the same pattern to an RLDS dataset and when using a Reverb table, see [this colab](https://colab.research.google.com/github/google-research/rlds/blob/main/rlds/examples/rlds_reverb_patterns.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DUQVrBsbDHA"
      },
      "outputs": [],
      "source": [
        "#@title Install Pip packages\n",
        "!pip install rlds[tensorflow]\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX2bty_P1qws"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import rlds\n",
        "import reverb\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyTwVENR26Pv"
      },
      "source": [
        "## Load a dataset to use throughout the examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_izO6IDuKc9G"
      },
      "source": [
        "Before experimenting with the patterns, we load a dataset to use through our examples. To experiment with other datasets, take a look at the available datasets in the [TFDS catalog](https://www.tensorflow.org/datasets/catalog/overview) and look for those that are RLDS-compatible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHiZ6haP2sfX"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'd4rl_mujoco_halfcheetah/v0-medium'  # @param\n",
        "num_episodes = 20  # @param\n",
        "\n",
        "dataset = tfds.load(dataset_name)['train'].take(num_episodes)\n",
        "\n",
        "step_spec = rlds.transformations.step_spec(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fngSva2774gt"
      },
      "source": [
        "# Reverb Patterns\n",
        "\n",
        "Reverb patterns are an API to transform streams of steps. The result is another stream of elements that can be, for example, transformed steps, transitions or trajectories.\n",
        "\n",
        "One pattern is actually a set of `configurations`, where each `configuration`\n",
        "consists of:\n",
        "* A transformation that specifies how the output is constructed. For example,\n",
        "\"take the observations from the last 5 steps\".\n",
        "* A set of conditions to decide whether to apply the pattern. For example, apply the pattern only to the first 10 steps of an episode.\n",
        "\n",
        "Besides, users can decide what is the behaviour when the stream of steps reaches the end of an episode: create output elements that contain data from different episodes, or not (in this case, each output element is guaranteed to contain only elements from one episode).\n",
        "\n",
        "**Note**: When constructing the pattern, we assume steps are being accumulated one by one in a queue, and we access the queue from the tail of the queue (see the examples below to understand exactly how it works). Everytime we insert a new step, we check all the conditions to decide if the pattern has to be applied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRCM0G5Y8RLS"
      },
      "source": [
        "## The Transformations\n",
        "\n",
        "The transformation is the part of the pattern that specifies how the steps are transformed to produce the output elements.\n",
        "\n",
        "The transformations express how the elements of the steps are grouped in order to construct the output elements. For example, we can construct SARS transitions by getting the observation of the last two steps, but the reward and action of only the previous-to-last step.\n",
        "\n",
        "However, the transformations do not allow operations with the step values. For example, if we want to build N-step transitions, we have to construct a transition that contains the sequence of N-1 rewards and discounts, but we cannot calculate directly the discounted reward using the patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDNBC63MPKGV"
      },
      "source": [
        "### Example 1: using  a reference spec.\n",
        "\n",
        "For example, the next transformation uses RLDS steps to produce SARS transitions.\n",
        " \n",
        "It first uses the `create_reference_step` to create a `reference step` from the spec of the steps dataset. This `reference_step` is then used to describe how the steps elements are used to construct a transition.\n",
        "\n",
        "**Note:** See how we access the elements from the end of the queue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jho4KfEt74Pu"
      },
      "outputs": [],
      "source": [
        "ref_step = reverb.structured_writer.create_reference_step(step_spec)\n",
        "\n",
        "sars_pattern = {\n",
        "    rlds.OBSERVATION:\n",
        "        tree.map_structure(lambda x: x[-2], ref_step[rlds.OBSERVATION]),\n",
        "    rlds.ACTION:\n",
        "        ref_step[rlds.ACTION][-2],\n",
        "    rlds.REWARD:\n",
        "        ref_step[rlds.REWARD][-2],\n",
        "    'next_observation':\n",
        "        tree.map_structure(lambda x: x[-1], ref_step[rlds.OBSERVATION]),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIshPluNTBMB"
      },
      "source": [
        "### Example 2: using a transformation\n",
        "\n",
        "Sometimes, it is more convenient to define a function with the transformation.\n",
        "\n",
        "This can be achieved by using `pattern_from_transform` (note that this call is\n",
        "not necessary if we use `rlds.transformations.pattern_map_from_transform`, see the [example](https://colab.research.google.com/github/google-research/rlds/blob/main/rlds/examples/rlds_dataset_patterns.ipynb#scrollTo=sO_vJobw3JVg) below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaNEwkjsWPdY"
      },
      "outputs": [],
      "source": [
        "def get_sars_pattern(step):\n",
        "  return {\n",
        "      rlds.OBSERVATION:\n",
        "          tree.map_structure(lambda x: x[-2], step[rlds.OBSERVATION]),\n",
        "      rlds.ACTION:\n",
        "          step[rlds.ACTION][-2],\n",
        "      rlds.REWARD:\n",
        "          step[rlds.REWARD][-2],\n",
        "      'next_observation':\n",
        "          tree.map_structure(lambda x: x[-1], step[rlds.OBSERVATION]),\n",
        "  }\n",
        "\n",
        "\n",
        "another_sars_pattern = reverb.structured_writer.pattern_from_transform(\n",
        "    step_spec, get_sars_pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgMbwutunLbf"
      },
      "source": [
        "## The Conditions\n",
        "\n",
        "The Patterns are formed by the transformation and a set of conditions to decide to which steps to apply the patterns.\n",
        "\n",
        "You can find a list of conditions and utils to define them in [here](https://github.com/deepmind/reverb/blob/7e9b5693572c18e484ee57329ea4d2019501904e/reverb/structured_writer.py#L431).\n",
        "\n",
        "By default, when creating a pattern, there is always an implicit condition: the number of steps in the buffer has to be enough to apply the transformation without causing Out-of-Bounds errors. For example, when constructing SARS transitions, we need at least two steps.\n",
        "\n",
        "**Note**: If you are creating large trajectories without allowing to merge episodes, and your episodes are short (e.g., you create 10-steps trajectories and all your episodes have 5 steps), the dataset will not generate any output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogc7BBTipUOW"
      },
      "source": [
        "### Example 1: Condition over the number of steps\n",
        "\n",
        "Use only the first 10 steps to produce a transition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dTtWVDJpazL"
      },
      "outputs": [],
      "source": [
        "condition_first_steps = reverb.structured_writer.Condition.step_index() \u003c 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acB-A4QZp2BL"
      },
      "source": [
        "### Example 2: Condition over the data\n",
        "\n",
        "It is also possible to apply a condition to data value, e.g., don't create transitions where the last observation belongs to a terminal state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irady9Ulp1Lm"
      },
      "outputs": [],
      "source": [
        "def condition_fn(step):\n",
        "  return step[rlds.IS_TERMINAL] == False\n",
        "\n",
        "\n",
        "condition_terminal = condition_fn(\n",
        "    reverb.structured_writer.Condition.data(step_spec))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8ZFiaV1ATiA"
      },
      "source": [
        "# Applying the Pattern\n",
        "\n",
        "By using the `PatternDataset` we apply the pattern to construct sars trajectories using only the first 10 steps of each episode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO_vJobw3JVg"
      },
      "source": [
        "## The Simplest Case: One Pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 9513,
          "status": "ok",
          "timestamp": 1653326114645,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "vxfe0F3E4KBU",
        "outputId": "63252e0a-e195-45ec-c2bd-f4952a877496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'action': \u003ctf.Tensor: shape=(6,), dtype=float32, numpy=\n",
            "array([ 0.98304164, -0.30126104,  0.3770365 ,  0.53884596, -0.94180214,\n",
            "       -0.158314  ], dtype=float32)\u003e, 'next_observation': \u003ctf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([-0.01038213, -0.02540122,  0.33964765, -0.1585834 ,  0.11570273,\n",
            "        0.25722653, -0.3806618 , -0.05179007,  1.0116358 , -0.6148436 ,\n",
            "       -0.09667274,  6.886969  , -5.4096785 ,  3.4446044 ,  7.0207024 ,\n",
            "       -7.125424  , -0.6964876 ], dtype=float32)\u003e, 'observation': \u003ctf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([ 0.00479665, -0.02969088,  0.06049511,  0.09577212, -0.01482561,\n",
            "       -0.0183125 , -0.06952589, -0.02880755,  0.18119103,  0.00390713,\n",
            "       -0.07221037, -0.06411345,  0.02970835, -0.12453649, -0.06031511,\n",
            "       -0.02463249,  0.02966032], dtype=float32)\u003e, 'reward': \u003ctf.Tensor: shape=(), dtype=float32, numpy=0.6067187\u003e}\n",
            "{'action': \u003ctf.Tensor: shape=(6,), dtype=float32, numpy=\n",
            "array([ 0.9912193 , -0.8879203 , -0.97937745, -0.9821982 , -0.9989058 ,\n",
            "       -0.9836019 ], dtype=float32)\u003e, 'next_observation': \u003ctf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([-4.2264987e-02, -1.1259432e-02,  5.7425582e-01, -4.6442339e-01,\n",
            "       -2.8399286e-01, -9.7864799e-02, -4.2673960e-01, -2.6651406e-01,\n",
            "       -5.1269352e-01, -8.3838379e-01,  6.0216206e-01,  2.0493133e+00,\n",
            "       -4.4994049e+00, -1.0997714e+01, -1.3850037e+01,  1.4051021e+00,\n",
            "       -5.7498422e+00], dtype=float32)\u003e, 'observation': \u003ctf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([-0.01038213, -0.02540122,  0.33964765, -0.1585834 ,  0.11570273,\n",
            "        0.25722653, -0.3806618 , -0.05179007,  1.0116358 , -0.6148436 ,\n",
            "       -0.09667274,  6.886969  , -5.4096785 ,  3.4446044 ,  7.0207024 ,\n",
            "       -7.125424  , -0.6964876 ], dtype=float32)\u003e, 'reward': \u003ctf.Tensor: shape=(), dtype=float32, numpy=-0.5301207\u003e}\n"
          ]
        }
      ],
      "source": [
        "pattern_dataset_rlds_simple = rlds.transformations.pattern_map_from_transform(\n",
        "    episodes_dataset=dataset,\n",
        "    transform_fn=get_sars_pattern,\n",
        "    # By setting this to true, we don't generate transitions that mix steps\n",
        "    # from two episodes.\n",
        "    respect_episode_boundaries=True,\n",
        ")\n",
        "\n",
        "for transition in pattern_dataset_rlds_simple.take(2):\n",
        "  print(transition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXLyHVII3xbH"
      },
      "source": [
        "## Applying a list of Patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRUeoCZa35tl"
      },
      "source": [
        "The examples below apply still one pattern, but the `configs` parameters in both cases take a list, so it's possible to apply more than one config."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw5o2Nsl12Pg"
      },
      "source": [
        "### Example 1: Using RLDS transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 22554,
          "status": "ok",
          "timestamp": 1653326153318,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "db7yMNVW18--",
        "outputId": "faefcbcd-d65a-4624-a549-fec11c1d3fd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'action': \u003ctf.Tensor: shape=(6,), dtype=float32, numpy=\n",
            "array([ 0.98304164, -0.30126104,  0.3770365 ,  0.53884596, -0.94180214,\n",
            "       -0.158314  ], dtype=float32)\u003e, 'next_observation': \u003ctf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([-0.01038213, -0.02540122,  0.33964765, -0.1585834 ,  0.11570273,\n",
            "        0.25722653, -0.3806618 , -0.05179007,  1.0116358 , -0.6148436 ,\n",
            "       -0.09667274,  6.886969  , -5.4096785 ,  3.4446044 ,  7.0207024 ,\n",
            "       -7.125424  , -0.6964876 ], dtype=float32)\u003e, 'observation': \u003ctf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([ 0.00479665, -0.02969088,  0.06049511,  0.09577212, -0.01482561,\n",
            "       -0.0183125 , -0.06952589, -0.02880755,  0.18119103,  0.00390713,\n",
            "       -0.07221037, -0.06411345,  0.02970835, -0.12453649, -0.06031511,\n",
            "       -0.02463249,  0.02966032], dtype=float32)\u003e, 'reward': \u003ctf.Tensor: shape=(), dtype=float32, numpy=0.6067187\u003e}\n",
            "{'action': \u003ctf.Tensor: shape=(6,), dtype=float32, numpy=\n",
            "array([ 0.9912193 , -0.8879203 , -0.97937745, -0.9821982 , -0.9989058 ,\n",
            "       -0.9836019 ], dtype=float32)\u003e, 'next_observation': \u003ctf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([-4.2264987e-02, -1.1259432e-02,  5.7425582e-01, -4.6442339e-01,\n",
            "       -2.8399286e-01, -9.7864799e-02, -4.2673960e-01, -2.6651406e-01,\n",
            "       -5.1269352e-01, -8.3838379e-01,  6.0216206e-01,  2.0493133e+00,\n",
            "       -4.4994049e+00, -1.0997714e+01, -1.3850037e+01,  1.4051021e+00,\n",
            "       -5.7498422e+00], dtype=float32)\u003e, 'observation': \u003ctf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([-0.01038213, -0.02540122,  0.33964765, -0.1585834 ,  0.11570273,\n",
            "        0.25722653, -0.3806618 , -0.05179007,  1.0116358 , -0.6148436 ,\n",
            "       -0.09667274,  6.886969  , -5.4096785 ,  3.4446044 ,  7.0207024 ,\n",
            "       -7.125424  , -0.6964876 ], dtype=float32)\u003e, 'reward': \u003ctf.Tensor: shape=(), dtype=float32, numpy=-0.5301207\u003e}\n"
          ]
        }
      ],
      "source": [
        "# The table is unused\n",
        "sars_config = reverb.structured_writer.create_config(\n",
        "    sars_pattern, table='transition', conditions=[condition_first_steps])\n",
        "\n",
        "pattern_dataset_rlds = rlds.transformations.pattern_map(\n",
        "    episodes_dataset=dataset,\n",
        "    configs=[sars_config],\n",
        "    # By setting this to true, we don't generate transitions that mix steps\n",
        "    # from two episodes.\n",
        "    respect_episode_boundaries=True,\n",
        ")\n",
        "\n",
        "for transition in pattern_dataset_rlds.take(2):\n",
        "  print(transition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvoPl0dy2BfH"
      },
      "source": [
        "### Example 2: Using the PatternDataset API directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 13180,
          "status": "ok",
          "timestamp": 1653326166522,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 0
        },
        "id": "lTn6XmuUwXjU",
        "outputId": "07881012-5de1-4224-bf52-b2d26e1665d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'action': \u003ctf.Tensor: shape=(6,), dtype=float32, numpy=\n",
            "array([ 0.98304164, -0.30126104,  0.3770365 ,  0.53884596, -0.94180214,\n",
            "       -0.158314  ], dtype=float32)\u003e, 'next_observation': \u003ctf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([-0.01038213, -0.02540122,  0.33964765, -0.1585834 ,  0.11570273,\n",
            "        0.25722653, -0.3806618 , -0.05179007,  1.0116358 , -0.6148436 ,\n",
            "       -0.09667274,  6.886969  , -5.4096785 ,  3.4446044 ,  7.0207024 ,\n",
            "       -7.125424  , -0.6964876 ], dtype=float32)\u003e, 'observation': \u003ctf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([ 0.00479665, -0.02969088,  0.06049511,  0.09577212, -0.01482561,\n",
            "       -0.0183125 , -0.06952589, -0.02880755,  0.18119103,  0.00390713,\n",
            "       -0.07221037, -0.06411345,  0.02970835, -0.12453649, -0.06031511,\n",
            "       -0.02463249,  0.02966032], dtype=float32)\u003e, 'reward': \u003ctf.Tensor: shape=(), dtype=float32, numpy=0.6067187\u003e}\n",
            "{'action': \u003ctf.Tensor: shape=(6,), dtype=float32, numpy=\n",
            "array([ 0.9912193 , -0.8879203 , -0.97937745, -0.9821982 , -0.9989058 ,\n",
            "       -0.9836019 ], dtype=float32)\u003e, 'next_observation': \u003ctf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([-4.2264987e-02, -1.1259432e-02,  5.7425582e-01, -4.6442339e-01,\n",
            "       -2.8399286e-01, -9.7864799e-02, -4.2673960e-01, -2.6651406e-01,\n",
            "       -5.1269352e-01, -8.3838379e-01,  6.0216206e-01,  2.0493133e+00,\n",
            "       -4.4994049e+00, -1.0997714e+01, -1.3850037e+01,  1.4051021e+00,\n",
            "       -5.7498422e+00], dtype=float32)\u003e, 'observation': \u003ctf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([-0.01038213, -0.02540122,  0.33964765, -0.1585834 ,  0.11570273,\n",
            "        0.25722653, -0.3806618 , -0.05179007,  1.0116358 , -0.6148436 ,\n",
            "       -0.09667274,  6.886969  , -5.4096785 ,  3.4446044 ,  7.0207024 ,\n",
            "       -7.125424  , -0.6964876 ], dtype=float32)\u003e, 'reward': \u003ctf.Tensor: shape=(), dtype=float32, numpy=-0.5301207\u003e}\n"
          ]
        }
      ],
      "source": [
        "# The table is unused\n",
        "sars_config = reverb.structured_writer.create_config(\n",
        "    sars_pattern, table='transition', conditions=[condition_first_steps])\n",
        "\n",
        "pattern_dataset = reverb.PatternDataset(\n",
        "    # We convert the dataset of episodes into a dataset of steps\n",
        "    input_dataset=dataset.flat_map(lambda e: e[rlds.STEPS]),\n",
        "    configs=[sars_config],\n",
        "    # By setting this to true, we don't generate transitions that mix steps\n",
        "    # from two episodes.\n",
        "    respect_episode_boundaries=True,\n",
        "    # We need to tell the dataset how to identify the end of an episode.\n",
        "    is_end_of_episode=lambda step: step[rlds.IS_LAST],\n",
        ")\n",
        "\n",
        "for transition in pattern_dataset.take(2):\n",
        "  print(transition)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "rlds_dataset_patterns.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
